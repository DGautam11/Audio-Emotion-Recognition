{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGautam11/Audio-Emotion-Recognition/blob/main/notebooks/02_wav2vec_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion Recognition using Wav2Vec2\n",
        "**Author:** Deepan Gautam (@Dpngtm)\n",
        "**Model:** [Hugging Face Link](https://huggingface.co/Dpngtm/wav2vec2-emotion-recognition)\n",
        "**Demo:** [Hugging Face Space](https://huggingface.co/spaces/Dpngtm/Audio-Emotion-Recognition)\n",
        "\n",
        "## Description\n",
        "This notebook fine-tunes Facebook's Wav2Vec2 model on 4 combined datasets (TESS, CREMA-D, SAVEE, RAVDESS) to recognize 7 emotions.\n",
        "**Accuracy Achieved:** ~80%"
      ],
      "metadata": {
        "id": "bYS-TJgna1Sv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0scDix1QW_4F"
      },
      "source": [
        "# Wav2Vec2 Fine-Tuning Workflow\n",
        "*End-to-end MLOps pipeline: Loading pre-processed features, fine-tuning the model, and deploying to Hugging Face Hub.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7W0-fz8wkJh"
      },
      "source": [
        "## ENVIRONMENT CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4V-7ec4WUU0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#  INSTALL TRAINING DEPENDENCIES\n",
        "!pip install datasets huggingface_hub transformers evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvwdcU_5XKI8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from datasets import load_from_disk\n",
        "from transformers import (\n",
        "    AutoModelForAudioClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from google.colab import drive\n",
        "from huggingface_hub import notebook_login\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d65hdC0Hwo8y"
      },
      "outputs": [],
      "source": [
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IS_COLAB = True\n",
        "    print(\"Detected Colab Environment. Using Google Drive.\")\n",
        "\n",
        "    # Colab Paths\n",
        "    # This must match where 01_data_preparation notebook saved the data\n",
        "    INPUT_PATH = \"/content/drive/MyDrive/wav2vec2-processed-data/\"\n",
        "    MODEL_OUTPUT_DIR = \"/content/drive/MyDrive/wav2vec2-emotion-checkpoints/\"\n",
        "    FINAL_MODEL_PATH = \"/content/drive/MyDrive/wav2vec2-emotion-final/\"\n",
        "\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "    print(\"Detected Local Environment. Using local storage.\")\n",
        "\n",
        "    # Local Paths (Relative to this notebook)\n",
        "    # Assumes data is in a folder next to the notebooks\n",
        "    INPUT_PATH = \"../wav2vec2-processed-data/\"\n",
        "    MODEL_OUTPUT_DIR = \"../checkpoints/\"\n",
        "    FINAL_MODEL_PATH = \"../final_model/\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_MODEL_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNlfTVhGYWNL"
      },
      "source": [
        "## 1. DATA LOADING (Ingest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI13CQV3Y3YK"
      },
      "outputs": [],
      "source": [
        "# Load Datasets\n",
        "print(\" Loading pre-tokenized datasets from disk...\")\n",
        "try:\n",
        "    train_dataset = load_from_disk(os.path.join(INPUT_PATH, \"train_dataset\"))\n",
        "    test_dataset = load_from_disk(os.path.join(INPUT_PATH, \"test_dataset\"))\n",
        "    print(f\" Data Loaded Successfully.\")\n",
        "    print(f\"   - Training Samples: {len(train_dataset)}\")\n",
        "    print(f\"   - Test Samples: {len(test_dataset)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\" ERROR: Could not find datasets. Run 01_data_prepration notebook and save to the correct path\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErT1PTSgzB5y"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Inspect the dataset to find out how many emotions we are predicting\n",
        "unique_labels = train_dataset.unique(\"labels\")\n",
        "num_labels = len(unique_labels)\n",
        "\n",
        "print(f\"Detected {num_labels} emotion classes.\")\n",
        "print(f\"   Classes: {unique_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdmgkGuO0g56"
      },
      "source": [
        "## 2. MODEL CONFIGURATION\n",
        "*Initializing pre-trained weights and configuring GPU acceleration.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYLgGvrt3yWl"
      },
      "source": [
        "### 2.1 Load Label Mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yXuE9FUB-T6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load the exact mapping created in 01_data_preparation notebook.\n",
        "label_file_path = os.path.join(INPUT_PATH, \"label_mapping.json\")\n",
        "\n",
        "try:\n",
        "    with open(label_file_path, \"r\") as f:\n",
        "        mappings = json.load(f)\n",
        "\n",
        "    # Convert keys back to integers (JSON stores them as strings)\n",
        "    id2label = {int(k): v for k, v in mappings[\"id2label\"].items()}\n",
        "    label2id = mappings[\"label2id\"]\n",
        "    num_labels = len(id2label)\n",
        "\n",
        "    print(f\"Loaded Label Mapping. Detected {num_labels} classes.\")\n",
        "    print(f\"   Mapping: {id2label}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    raise RuntimeError(\"label_mapping.json not found! Please re-run 01_data_preparation notebook\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-DTpL5FHhdS"
      },
      "source": [
        "### 2.2 Device Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Ne1OjoDmR4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\" Active Computation Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyV_FGxnHoG4"
      },
      "source": [
        "### 2.2 Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyqr0Q6FHnGY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Loading Facebook's Wav2Vec2 base model with a classification head on top\n",
        "model = AutoModelForAudioClassification.from_pretrained(\n",
        "    'facebook/wav2vec2-base-960h',\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "model.freeze_feature_extractor()\n",
        "\n",
        "model.to(device) # Move weights to GPU\n",
        "print(\"Model initialized and moved to GPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65ZQlyDAMIeg"
      },
      "source": [
        "### 3. TRAINING CONFIFURATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwAUclETMW7p"
      },
      "source": [
        "#### 3.1 Set Format to PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AknuG3ZWLa7p"
      },
      "outputs": [],
      "source": [
        "# The model requires PyTorch Tensors, not Python Lists.\n",
        "\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_values\", \"labels\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_values\", \"labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKjqY-mKMfMn"
      },
      "source": [
        "#### 3.2 Define Metrics Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5nsYwN8MSQ5"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    #  calculate both Accuracy and F1-Score\n",
        "    # 'weighted' F1 is best for multi-class emotion classification\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFMxGE1yNwEX"
      },
      "source": [
        "#### 3.3 Setup Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdEyB4X1zwZE"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= MODEL_OUTPUT_DIR,\n",
        "    overwrite_output_dir=True,\n",
        "\n",
        "\n",
        "    learning_rate=3e-5,             # safer for a frozen model\n",
        "    num_train_epochs=10,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        "\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,  # Effective Batch Size = 16\n",
        "    fp16=False,                     # Keep False for (T4 GPU stability)\n",
        "    gradient_checkpointing=False,\n",
        "\n",
        "    # --- LOGGING ---\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hU1iVxdRWGI"
      },
      "source": [
        "### 4. MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGaqHuxURH1n"
      },
      "outputs": [],
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JsbN3QkSOO9"
      },
      "outputs": [],
      "source": [
        "#Start Training\n",
        "print(\"Starting training process...\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. PUSH TO HUGGING FACE SPACES"
      ],
      "metadata": {
        "id": "cVbU4dD_gpKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Get the token from Secrets\n",
        "from google.colab import userdata\n",
        "from transformers import Wav2Vec2Processor\n",
        "\n",
        "try:\n",
        "    #  REPLACE 'HF_TOKEN' WITH THE EXACT NAME YOU GAVE IT IN THE SECRETS TAB\n",
        "    my_token = userdata.get('HF_TOKEN')\n",
        "    print(\"Token retrieved from Secrets successfully.\")\n",
        "except:\n",
        "    print(\"Error: Could not find the token. Check the name in the Secrets tab (Key icon).\")\n",
        "\n",
        "\n",
        "# 2. Define Repo\n",
        "repo_id = \"Dpngtm/wav2vec2-emotion-recognition\"\n",
        "\n",
        "# 3. Reload Processor (Standard safety step)\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "# 4. Push using the token explicitly\n",
        "print(f\"Pushing to {repo_id}...\")\n",
        "\n",
        "model.push_to_hub(repo_id, token=my_token)\n",
        "processor.push_to_hub(repo_id, token=my_token)\n",
        "\n",
        "print(\"SUCCESS! Upload finished.\")"
      ],
      "metadata": {
        "id": "U4nZe-3EYtC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNiLKYfmVAP4wqZtQs9zY/J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}